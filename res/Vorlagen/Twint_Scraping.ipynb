{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install nest_asyncio\n",
    "\n",
    "git clone --depth=1 https://github.com/twintproject/twint.git<br>\n",
    "cd twint<br>\n",
    "pip3 install . -r requirements.txt<br>\n",
    "\n",
    "+ aiohttp==3.7.0 setzen in requirements.txt\n",
    "\n",
    "python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import schedule\n",
    "import time\n",
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "c = twint.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellt aus String eine Liste\n",
    "from ast import literal_eval\n",
    "import re\n",
    "def extract_reply_to(stringliste):\n",
    "    if len(stringliste) > 10:\n",
    "        mentionsliste = []\n",
    "        liste = literal_eval(stringliste)\n",
    "        for mention in liste:\n",
    "            mentionsliste.append(mention[\"screen_name\"])\n",
    "        return mentionsliste\n",
    "    else:\n",
    "        return stringliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchTwint(keyword, since=None, until=None, language=None, limit=None, createDataFrame=True, hide_out=True):\n",
    "    c = twint.Config()\n",
    "    c.Search = \"{} lang:{}\".format(keyword, language)\n",
    "    c.Filter_retweets = False\n",
    "    if language is not None:\n",
    "        c.Lang = language\n",
    "    if since is not None:\n",
    "        c.Since = since\n",
    "    if until is not None:\n",
    "        c.Until = until\n",
    "    if limit is not None:\n",
    "        c.Limit = limit\n",
    "    c.Hide_output = hide_out\n",
    "    if createDataFrame:\n",
    "        c.Pandas = True\n",
    "    twint.run.Search(c)\n",
    "    if createDataFrame:\n",
    "        Tweets_df = twint.storage.panda.Tweets_df\n",
    "        return Tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = searchTwint(\"corona\", since=\"2022-05-27\", until=\"2022-05-29\", language=\"de\", limit=1000, createDataFrame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplikate werden entfernt\n",
    "df = df.drop_duplicates(subset=[\"id\"])\n",
    "df.drop(columns=[\"created_at\", \"place\", \"cashtags\", \"user_id_str\", \"day\", \"hour\", \"urls\", \"thumbnail\", \"quote_url\", \"near\", \"geo\", \"source\", \"user_rt_id\", \"user_rt\", \"retweet_id\", \"retweet\", \"retweet_date\", \"translate\", \"trans_src\", \"trans_dest\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"language\"] == \"de\"]\n",
    "df[\"date\"] = df[\"date\"].astype(\"datetime64\")\n",
    "#df[\"created_at\"] = df[\"created_at\"].astype(\"datetime64\")\n",
    "df[\"Wochentag\"] = df[\"date\"].apply(lambda x: x.weekday())\n",
    "df[\"Stunde\"] = df[\"date\"].apply(lambda x: x.hour)\n",
    "df[\"Originale_Tweetlaenge\"] = df[\"tweet\"].apply(lambda x: len(x))\n",
    "#df[\"reply_to\"] = df[\"reply_to\"].apply(lambda x: str(extract_reply_to(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>photos</th>\n",
       "      <th>video</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "      <th>search</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>Wochentag</th>\n",
       "      <th>Stunde</th>\n",
       "      <th>Originale_Tweetlaenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1530699449323995136</td>\n",
       "      <td>1530699449323995136</td>\n",
       "      <td>2022-05-29 01:56:02</td>\n",
       "      <td>+0200</td>\n",
       "      <td>Der wahre Feind für den Bürger ist die Abwesen...</td>\n",
       "      <td>de</td>\n",
       "      <td>[corona, demokratie, ifsg]</td>\n",
       "      <td>1530150359691411456</td>\n",
       "      <td>FionaIamBack</td>\n",
       "      <td>Fiona</td>\n",
       "      <td>https://twitter.com/FionaIamBack/status/153069...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530699272844460032</td>\n",
       "      <td>1530699272844460032</td>\n",
       "      <td>2022-05-29 01:55:20</td>\n",
       "      <td>+0200</td>\n",
       "      <td>Maskenpflicht und weitere Maßnahmen: RKI-Chef ...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>326899497</td>\n",
       "      <td>Ostseeolaf</td>\n",
       "      <td>Ostseeolaf</td>\n",
       "      <td>https://twitter.com/Ostseeolaf/status/15306992...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1530698754969550849</td>\n",
       "      <td>1530698754969550849</td>\n",
       "      <td>2022-05-29 01:53:16</td>\n",
       "      <td>+0200</td>\n",
       "      <td>Tanzen als ob Corona nur Fake News ist. Nobody...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>1325940815592648704</td>\n",
       "      <td>GraffityJimmy</td>\n",
       "      <td>Jimmy Graffity</td>\n",
       "      <td>https://twitter.com/GraffityJimmy/status/15306...</td>\n",
       "      <td>[https://pbs.twimg.com/media/FT4iZb9XEAQuy9a.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1530697203643297792</td>\n",
       "      <td>1530596403453513728</td>\n",
       "      <td>2022-05-29 01:47:06</td>\n",
       "      <td>+0200</td>\n",
       "      <td>@_MartinHagen @c_lindner @focusonline Die @FDP...</td>\n",
       "      <td>de</td>\n",
       "      <td>[fdprausausderregierung, fdprausausdenparlamen...</td>\n",
       "      <td>3378490043</td>\n",
       "      <td>dannyalgaaf</td>\n",
       "      <td>Danny Al-Gaaf</td>\n",
       "      <td>https://twitter.com/dannyalgaaf/status/1530697...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[{'screen_name': '_MartinHagen', 'name': 'Mart...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1530696675605504002</td>\n",
       "      <td>1530653076239138817</td>\n",
       "      <td>2022-05-29 01:45:01</td>\n",
       "      <td>+0200</td>\n",
       "      <td>@chguettler Wegen Corona verlieren die Wenigst...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>1488993896</td>\n",
       "      <td>gunder42</td>\n",
       "      <td>aRGy</td>\n",
       "      <td>https://twitter.com/gunder42/status/1530696675...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[{'screen_name': 'chguettler', 'name': 'Chris'...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>1530597854313689089</td>\n",
       "      <td>1530526561715224578</td>\n",
       "      <td>2022-05-28 19:12:20</td>\n",
       "      <td>+0200</td>\n",
       "      <td>@karla__kraus @MeyerMeike Es ist Dummheit. Tro...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>1495686600558317571</td>\n",
       "      <td>TheThickPen</td>\n",
       "      <td>The Thick Pen 💉💉😷💉💉</td>\n",
       "      <td>https://twitter.com/TheThickPen/status/1530597...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[{'screen_name': 'karla__kraus', 'name': '🇺🇦 K...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1530597818393677824</td>\n",
       "      <td>1530555290600493056</td>\n",
       "      <td>2022-05-28 19:12:11</td>\n",
       "      <td>+0200</td>\n",
       "      <td>@nenacasc @annewill Anne Will hat bisher mehr ...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>1355233260163489792</td>\n",
       "      <td>KirchJurgen</td>\n",
       "      <td>Jürgen Kirch</td>\n",
       "      <td>https://twitter.com/KirchJurgen/status/1530597...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[{'screen_name': 'nenacasc', 'name': 'NENA SCH...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1530597736881471491</td>\n",
       "      <td>1529002686997315585</td>\n",
       "      <td>2022-05-28 19:11:52</td>\n",
       "      <td>+0200</td>\n",
       "      <td>@Karl_Lauterbach ich hab mich früher nie für P...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>15944982</td>\n",
       "      <td>valshare</td>\n",
       "      <td>valshare</td>\n",
       "      <td>https://twitter.com/valshare/status/1530597736...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[{'screen_name': 'Karl_Lauterbach', 'name': 'P...</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1530597629201108999</td>\n",
       "      <td>1530597629201108999</td>\n",
       "      <td>2022-05-28 19:11:26</td>\n",
       "      <td>+0200</td>\n",
       "      <td>Bin immer noch nicht von #Affenpocken befallen...</td>\n",
       "      <td>de</td>\n",
       "      <td>[affenpocken, corona, grippe, corona, geimpft,...</td>\n",
       "      <td>1433048619452612608</td>\n",
       "      <td>9Incide</td>\n",
       "      <td>Inside ♒</td>\n",
       "      <td>https://twitter.com/9Incide/status/15305976292...</td>\n",
       "      <td>[https://pbs.twimg.com/media/FT3Gbr2WIAA1JN6.jpg]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1530597470329249792</td>\n",
       "      <td>1530597470329249792</td>\n",
       "      <td>2022-05-28 19:10:48</td>\n",
       "      <td>+0200</td>\n",
       "      <td>Seitdem ich corona hatte ist meine lunge bei d...</td>\n",
       "      <td>de</td>\n",
       "      <td>[]</td>\n",
       "      <td>1419410257248411653</td>\n",
       "      <td>dilaaaraAk</td>\n",
       "      <td>Dilara</td>\n",
       "      <td>https://twitter.com/dilaaaraAk/status/15305974...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corona lang:de</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id      conversation_id                date timezone  \\\n",
       "0     1530699449323995136  1530699449323995136 2022-05-29 01:56:02    +0200   \n",
       "1     1530699272844460032  1530699272844460032 2022-05-29 01:55:20    +0200   \n",
       "2     1530698754969550849  1530698754969550849 2022-05-29 01:53:16    +0200   \n",
       "3     1530697203643297792  1530596403453513728 2022-05-29 01:47:06    +0200   \n",
       "4     1530696675605504002  1530653076239138817 2022-05-29 01:45:01    +0200   \n",
       "...                   ...                  ...                 ...      ...   \n",
       "1012  1530597854313689089  1530526561715224578 2022-05-28 19:12:20    +0200   \n",
       "1013  1530597818393677824  1530555290600493056 2022-05-28 19:12:11    +0200   \n",
       "1014  1530597736881471491  1529002686997315585 2022-05-28 19:11:52    +0200   \n",
       "1015  1530597629201108999  1530597629201108999 2022-05-28 19:11:26    +0200   \n",
       "1016  1530597470329249792  1530597470329249792 2022-05-28 19:10:48    +0200   \n",
       "\n",
       "                                                  tweet language  \\\n",
       "0     Der wahre Feind für den Bürger ist die Abwesen...       de   \n",
       "1     Maskenpflicht und weitere Maßnahmen: RKI-Chef ...       de   \n",
       "2     Tanzen als ob Corona nur Fake News ist. Nobody...       de   \n",
       "3     @_MartinHagen @c_lindner @focusonline Die @FDP...       de   \n",
       "4     @chguettler Wegen Corona verlieren die Wenigst...       de   \n",
       "...                                                 ...      ...   \n",
       "1012  @karla__kraus @MeyerMeike Es ist Dummheit. Tro...       de   \n",
       "1013  @nenacasc @annewill Anne Will hat bisher mehr ...       de   \n",
       "1014  @Karl_Lauterbach ich hab mich früher nie für P...       de   \n",
       "1015  Bin immer noch nicht von #Affenpocken befallen...       de   \n",
       "1016  Seitdem ich corona hatte ist meine lunge bei d...       de   \n",
       "\n",
       "                                               hashtags              user_id  \\\n",
       "0                            [corona, demokratie, ifsg]  1530150359691411456   \n",
       "1                                                    []            326899497   \n",
       "2                                                    []  1325940815592648704   \n",
       "3     [fdprausausderregierung, fdprausausdenparlamen...           3378490043   \n",
       "4                                                    []           1488993896   \n",
       "...                                                 ...                  ...   \n",
       "1012                                                 []  1495686600558317571   \n",
       "1013                                                 []  1355233260163489792   \n",
       "1014                                                 []             15944982   \n",
       "1015  [affenpocken, corona, grippe, corona, geimpft,...  1433048619452612608   \n",
       "1016                                                 []  1419410257248411653   \n",
       "\n",
       "           username                 name  \\\n",
       "0      FionaIamBack                Fiona   \n",
       "1        Ostseeolaf           Ostseeolaf   \n",
       "2     GraffityJimmy       Jimmy Graffity   \n",
       "3       dannyalgaaf        Danny Al-Gaaf   \n",
       "4          gunder42                 aRGy   \n",
       "...             ...                  ...   \n",
       "1012    TheThickPen  The Thick Pen 💉💉😷💉💉   \n",
       "1013    KirchJurgen         Jürgen Kirch   \n",
       "1014       valshare             valshare   \n",
       "1015        9Incide             Inside ♒   \n",
       "1016     dilaaaraAk               Dilara   \n",
       "\n",
       "                                                   link  \\\n",
       "0     https://twitter.com/FionaIamBack/status/153069...   \n",
       "1     https://twitter.com/Ostseeolaf/status/15306992...   \n",
       "2     https://twitter.com/GraffityJimmy/status/15306...   \n",
       "3     https://twitter.com/dannyalgaaf/status/1530697...   \n",
       "4     https://twitter.com/gunder42/status/1530696675...   \n",
       "...                                                 ...   \n",
       "1012  https://twitter.com/TheThickPen/status/1530597...   \n",
       "1013  https://twitter.com/KirchJurgen/status/1530597...   \n",
       "1014  https://twitter.com/valshare/status/1530597736...   \n",
       "1015  https://twitter.com/9Incide/status/15305976292...   \n",
       "1016  https://twitter.com/dilaaaraAk/status/15305974...   \n",
       "\n",
       "                                                 photos  video  nlikes  \\\n",
       "0                                                    []      0       4   \n",
       "1                                                    []      0       0   \n",
       "2     [https://pbs.twimg.com/media/FT4iZb9XEAQuy9a.jpg]      1       1   \n",
       "3                                                    []      0      18   \n",
       "4                                                    []      0       2   \n",
       "...                                                 ...    ...     ...   \n",
       "1012                                                 []      0       1   \n",
       "1013                                                 []      0       2   \n",
       "1014                                                 []      0       0   \n",
       "1015  [https://pbs.twimg.com/media/FT3Gbr2WIAA1JN6.jpg]      1       2   \n",
       "1016                                                 []      0       5   \n",
       "\n",
       "      nreplies  nretweets          search  \\\n",
       "0            0          1  corona lang:de   \n",
       "1            2          4  corona lang:de   \n",
       "2            0          0  corona lang:de   \n",
       "3            0          2  corona lang:de   \n",
       "4            0          0  corona lang:de   \n",
       "...        ...        ...             ...   \n",
       "1012         0          0  corona lang:de   \n",
       "1013         0          0  corona lang:de   \n",
       "1014         0          0  corona lang:de   \n",
       "1015         1          1  corona lang:de   \n",
       "1016         0          0  corona lang:de   \n",
       "\n",
       "                                               reply_to  Wochentag  Stunde  \\\n",
       "0                                                    []          6       1   \n",
       "1                                                    []          6       1   \n",
       "2                                                    []          6       1   \n",
       "3     [{'screen_name': '_MartinHagen', 'name': 'Mart...          6       1   \n",
       "4     [{'screen_name': 'chguettler', 'name': 'Chris'...          6       1   \n",
       "...                                                 ...        ...     ...   \n",
       "1012  [{'screen_name': 'karla__kraus', 'name': '🇺🇦 K...          5      19   \n",
       "1013  [{'screen_name': 'nenacasc', 'name': 'NENA SCH...          5      19   \n",
       "1014  [{'screen_name': 'Karl_Lauterbach', 'name': 'P...          5      19   \n",
       "1015                                                 []          5      19   \n",
       "1016                                                 []          5      19   \n",
       "\n",
       "      Originale_Tweetlaenge  \n",
       "0                        95  \n",
       "1                       158  \n",
       "2                       174  \n",
       "3                       279  \n",
       "4                       163  \n",
       "...                     ...  \n",
       "1012                    305  \n",
       "1013                    175  \n",
       "1014                    282  \n",
       "1015                    304  \n",
       "1016                     72  \n",
       "\n",
       "[1017 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@welt Ich fordere dass mich die Corona-Freaks bitte dauerhaft in Ruhe lassen sollen, mit ihrer Paranoia. Ich glaube nicht dass ich abkratzen werde, wenn ich im Winter mal ein paar Tage einen Omikron Schnupfen habe.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10][\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MeineProgramme\\Anaconda\\envs\\bdcc\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from typing import List\n",
    "import torch\n",
    "import re\n",
    "\n",
    "class SentimentModel():\n",
    "    def __init__(self, model_name):\n",
    "        self.device = \"cpu\"\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name).to(self.device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Cleaning with Regex\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\\\S+', re.MULTILINE)\n",
    "\n",
    "    def predict_sentiment(self, texts):\n",
    "        texts = [self.clean_text(text) for text in texts]\n",
    "        # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "        encoded = self.tokenizer.batch_encode_plus(texts,padding=True, add_special_tokens=True,truncation=True, return_tensors=\"pt\")\n",
    "        encoded = encoded.to(self.device)\n",
    "        with torch.no_grad():\n",
    "                logits = self.model(**encoded)\n",
    "        \n",
    "        label_ids = torch.argmax(logits[0], axis=1)\n",
    "        return [self.model.config.id2label[label_id.item()] for label_id in label_ids]\n",
    "\n",
    "    # def replace_numbers(self,text: str) -> str:\n",
    "    #         return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\").replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\").replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\").replace(\"9\",\" neun\")         \n",
    "\n",
    "    def clean_text(self, text):\n",
    "            text = text.replace(\"\\n\", \" \")        \n",
    "            text = self.clean_http_urls.sub('',text)\n",
    "            text = self.clean_at_mentions.sub('',text)        \n",
    "            #text = self.replace_numbers(text)                \n",
    "            text = self.clean_chars.sub('', text) # use only text chars                          \n",
    "            text = ' '.join(text.split()) # substitute multiple whitespace with single whitespace   \n",
    "            text = text.strip().lower()\n",
    "            return text\n",
    "\n",
    "# texts = [\"Mit keinem guten Ergebniss\",\"Das war unfair\", \"Das ist gar nicht mal so gut\",\n",
    "#         \"Total awesome!\",\"nicht so schlecht wie erwartet\", \"Das ist gar nicht mal so schlecht\",\n",
    "#         \"Der Test verlief positiv.\",\"Sie fährt ein grünes Auto.\", \"Der Fall wurde an die Polzei übergeben.\"]\n",
    "\n",
    "model = SentimentModel(model_name = \"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "#print(model.predict_sentiment(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten müssen gesplittet werden, um in den Speicher zu passen\n",
    "def split_dataframe(df, chunk_size = 1000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prozent:  1.0324483775811208\n",
      "Genau:  1050  /  1017\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Durchlaufen des Modells\n",
    "ergebnisliste = []\n",
    "laenge = len(df)\n",
    "chunksize = 50\n",
    "for i, x in enumerate(split_dataframe(df, chunksize)):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Prozent: \", (i+1)*chunksize / laenge)\n",
    "    print(\"Genau: \", (i+1)*chunksize, \" / \", laenge)\n",
    "    ergebnisliste.append(model.predict_sentiment(x[\"tweet\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "newListTMP = list(itertools.chain(*ergebnisliste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"] = newListTMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping\n",
    "def mapsenti(x):\n",
    "    if x == \"negative\":\n",
    "        return -1\n",
    "    if x == \"positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BertSentimentNumber\"] = df[\"Sentiment\"].apply(lambda x: mapsenti(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob_de import TextBlobDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hahnb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "\"Der Blob\" macht in seiner unbekümmert-naiven Weise einfach nur Spass.\n",
    "Er hat eben den gewissen Charme, bei dem auch die eher hölzerne Regie und\n",
    "das konfuse Drehbuch nicht weiter stören. Ich hasse mein Leben.\n",
    "'''\n",
    "\n",
    "blob = TextBlobDE(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes trainieren\n",
    "https://textblob-de.readthedocs.io/en/latest/api_reference.html#module-textblob_de.sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "898d9c94b18329058d1bddabb506966d01c3b0563df60dbc5013fa756477016a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('bdcc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
