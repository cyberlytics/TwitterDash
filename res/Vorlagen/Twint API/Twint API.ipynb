{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expected-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import twint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import schedule\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blind-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywordliste einlesen\n",
    "def readKeywordFile(file):\n",
    "    keywords = []\n",
    "    with open(file, \"r\") as filestream:\n",
    "        for i, line in enumerate(filestream):\n",
    "            currentline = line.split(\",\")\n",
    "            for eintrag in currentline:\n",
    "                keywords.append(eintrag.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"ae\", \"ä\").replace(\"oe\", \"ö\").replace(\"ue\", \"ü\"))\n",
    "    return list(filter(None, keywords))\n",
    "\n",
    "# Twitter durchsuchen nach Keyword mit Parametern\n",
    "def searchTwitterTwint(keyword, since=None, until=None, language=None, limit=None, outputFile=False, outputFileName=\"\", outputFolder=\"\", createDataFrame=True, hide_out=True):\n",
    "    c = twint.Config()\n",
    "    c.Search = keyword\n",
    "    c.Filter_retweets = False\n",
    "    if language is not None:\n",
    "        c.Lang = language\n",
    "    if since is not None:\n",
    "        c.Since = since\n",
    "    if until is not None:\n",
    "        c.Until = until\n",
    "    if limit is not None:\n",
    "        c.Limit = limit\n",
    "    c.Hide_output = hide_out\n",
    "    if outputFile:\n",
    "        c.Store_csv = True\n",
    "        if outputFile == \"\":\n",
    "            outputFile = \"Default\"\n",
    "        if outputFolder == \"\":\n",
    "            outputFolder = \"data\"\n",
    "        #c.Output = \"{}.csv\".format(outputFileName)\n",
    "        c.Output = os.path.join('../Daten/TwintApi/{}/{}.csv'.format(outputFolder, outputFileName))\n",
    "    if createDataFrame:\n",
    "        c.Pandas = True\n",
    "    twint.run.Search(c)\n",
    "    if createDataFrame:\n",
    "        Tweets_df = twint.storage.panda.Tweets_df\n",
    "        return Tweets_df\n",
    "        \n",
    "# Für den vorherigen Tag alle Tweets der Keywordliste farmen    \n",
    "def job_EveryDay(keywords):\n",
    "    schedule.clear()\n",
    "    clear_output(wait=True)\n",
    "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    yesterday = (datetime.datetime.now() - pd.to_timedelta(1,'d')).strftime(\"%Y-%m-%d\")\n",
    "    if not os.path.exists(\"../Daten/TwintApi/{}\".format(yesterday)):\n",
    "        os.mkdir(\"../Daten/TwintApi/{}\".format(yesterday))\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Akutelles Keyword: \", keyword)\n",
    "        #filename = \"{}_{}\".format(yesterday, i) # Nummer\n",
    "        filename = \"{}_{}\".format(yesterday, keyword)  # Keyword\n",
    "        searchTwitterTwint(createDataFrame=False, language=\"de\", keyword=\"{} lang:de\".format(keyword), since=yesterday, until=today, hide_out=True, outputFile=True, outputFileName=filename, outputFolder=yesterday)\n",
    "        time.sleep(1)\n",
    "\n",
    "# Alle Tweets der Keywordliste von einem Datum farmen        \n",
    "def getTwitterFromDay(date, keywords):\n",
    "    clear_output(wait=True)\n",
    "    yesterday = datetime.datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "    till = (datetime.datetime.strptime(date, \"%Y-%m-%d\") + pd.to_timedelta(1,'d')).strftime(\"%Y-%m-%d\")\n",
    "    #print(\"Daten zwischen: \", yesterday, \" : \", till)\n",
    "    if not os.path.exists(\"../Daten/TwintApi/{}\".format(yesterday)):\n",
    "        os.mkdir(\"../Daten/TwintApi/{}\".format(yesterday))\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Daten zwischen: \", yesterday, \" : \", till)\n",
    "        print(\"Akutelles Keyword: \", keyword)\n",
    "        #filename = \"{}_{}\".format(yesterday, i) # Nummer\n",
    "        filename = \"{}_{}\".format(yesterday, keyword)  # Keyword\n",
    "        searchTwitterTwint(createDataFrame=False, language=\"de\", keyword=\"{} lang:de\".format(keyword), since=yesterday, until=till, hide_out=True, outputFile=True, outputFileName=filename, outputFolder=yesterday)\n",
    "        time.sleep(1)\n",
    "\n",
    "# Alle Tweets der Keywordliste in einem Zeitbereich farmen       \n",
    "def getTwitterBetweenDates(fromDate, tillDate, keywords):\n",
    "    fromThisDate = datetime.datetime.strptime(fromDate, \"%Y-%m-%d\")\n",
    "    toThisDate = datetime.datetime.strptime(tillDate, \"%Y-%m-%d\")\n",
    "    listWithDates = pd.date_range(fromThisDate,(toThisDate-pd.to_timedelta(1,'d')),freq='d')\n",
    "    #print(listWithDates[0].strftime(\"%Y-%m-%d\"))\n",
    "    for date in listWithDates:\n",
    "        getTwitterFromDay(date.strftime(\"%Y-%m-%d\"), keywords)\n",
    "    print(\"Ende\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recorded-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = readKeywordFile(\"./KeywordsGER.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demographic-helicopter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Akutelles Keyword:  #fdp\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "job_EveryDay(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every().day.at(\"12:00\").do(job_EveryDay, keywords)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60) # Check every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "assigned-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTwitterFromDay(\"2021-03-10\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agricultural-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTwitterBetweenDates(\"2021-01-01\", \"2021-03-29\", keywords[234:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "d8b32da32ca45bacd67e9a08daee70a5eca111f4e7e40040cf40975fa2bf4d1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}