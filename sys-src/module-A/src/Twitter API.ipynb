{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-testimony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import tweepy as tw\n",
    "from tweepy import TweepError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import datetime\n",
    "import schedule\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import urllib3.contrib.pyopenssl\n",
    "urllib3.contrib.pyopenssl.inject_into_urllib3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addressed-puzzle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Für Twitter API --> Developer Account\n",
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= ''\n",
    "access_token_secret= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-patent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Eigene Methoden für das Erstellen von Dateien --> Methoden sagen eigentlich schon aus, was gemacht wird\n",
    "# Ratenlimitierung der Twitter API wird im Auge gehalten\n",
    "def test_rate_limit(api, wait=True, buffer=.1):\n",
    "    try:\n",
    "        remaining = int(api.last_response.headers['x-rate-limit-remaining'])\n",
    "        print(\"Remaining:\", remaining)\n",
    "        limit = int(api.last_response.headers['x-rate-limit-limit'])\n",
    "        print(\"Limit: \", limit)\n",
    "        reset = int(api.last_response.headers['x-rate-limit-reset'])\n",
    "        resetdate = datetime.datetime.fromtimestamp(reset)\n",
    "        print(\"Reset: \", resetdate)\n",
    "        return True\n",
    "    except:\n",
    "        print()\n",
    "        \n",
    "# Sucht Tweet\n",
    "def searchTwitterAPI(keyword, since, until, quantity = None, language=\"de\"):\n",
    "    if quantity == None:\n",
    "        tweets = tw.Cursor(api.search, q=\"{} since:{}, until:{}\".format(keyword, since, until), count=100, result_type=\"recent\", lang=language, tweet_mode=\"extended\").items()\n",
    "        #tweets = tw.Cursor(api.search, q=\"{} since:{}, until:{}, exclude:retweets\".format(keyword, since, until), count=100, result_type=\"recent\", lang=language, tweet_mode=\"extended\").items()\n",
    "    else:\n",
    "        tweets = tw.Cursor(api.search, q=\"{} since:{}, until:{}\".format(keyword, since, until), count=100, result_type=\"recent\", lang=language, tweet_mode=\"extended\").items(quantity)\n",
    "        #tweets = tw.Cursor(api.search, q=\"{} since:{}, until:{}, exclude:retweets\".format(keyword, since, until), count=100, result_type=\"recent\", lang=language, tweet_mode=\"extended\").items(quantity)\n",
    "    tweetlist = []\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        print(\"Aktuelles Keyword: \", keyword)\n",
    "        print(\"Anzahl: \", i)\n",
    "        test_rate_limit(api)\n",
    "        clear_output(wait=True)\n",
    "        tweetlist.append(tweet)\n",
    "    print(\"Transforming to json\")\n",
    "    json_data = [r._json for r in tweetlist]\n",
    "    return pd.json_normalize(json_data)\n",
    "\n",
    "# Liest die Keywordliste\n",
    "def readKeywordFile(file):\n",
    "    keywords = []\n",
    "    with open(file, \"r\") as filestream:\n",
    "        for i, line in enumerate(filestream):\n",
    "            currentline = line.split(\",\")\n",
    "            for eintrag in currentline:\n",
    "                keywords.append(eintrag.replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"ae\", \"ä\").replace(\"oe\", \"ö\").replace(\"ue\", \"ü\"))\n",
    "    return list(filter(None, keywords))\n",
    "\n",
    "# Holt sich alle Tweets für einen Tag mit der Keywordliste\n",
    "def job_EveryDay(keywords):\n",
    "    schedule.clear()\n",
    "    clear_output(wait=True)\n",
    "    today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    yesterday = (datetime.datetime.now() - pd.to_timedelta(1,'d')).strftime(\"%Y-%m-%d\")\n",
    "    if not os.path.exists(\"../Daten/TwitterApi/{}\".format(yesterday)):\n",
    "        os.mkdir(\"../Daten/TwitterApi/{}\".format(yesterday))\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        #filename = \"{}_{}\".format(yesterday, i) # Nummer\n",
    "        filename = \"{}_{}\".format(yesterday, keyword)  # Keyword\n",
    "        searchTwitterAPI(keyword=keyword, since=yesterday, until=today).to_csv(\"../Daten/TwitterApi/{}/{}.csv\".format(yesterday, filename), sep = ';', line_terminator = '', encoding = 'utf-8')\n",
    "    print(\"Ende\")\n",
    "\n",
    "# Holt sich von einen bestimmten Tag mit einer bestimmten Keywordliste Tweets    \n",
    "def getTwitterFromDay(date, keywords):\n",
    "    clear_output(wait=True)\n",
    "    yesterday = datetime.datetime.strptime(date, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "    till = (datetime.datetime.strptime(date, \"%Y-%m-%d\") + pd.to_timedelta(1,'d')).strftime(\"%Y-%m-%d\")\n",
    "    #print(\"Daten zwischen: \", yesterday, \" : \", till)\n",
    "    if not os.path.exists(\"../Daten/TwitterApi/{}\".format(yesterday)):\n",
    "        os.mkdir(\"../Daten/TwitterApi/{}\".format(yesterday))\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Daten zwischen: \", yesterday, \" : \", till)\n",
    "        print(\"Akutelles Keyword: \", keyword)\n",
    "        #filename = \"{}_{}\".format(yesterday, i) # Nummer\n",
    "        filename = \"{}_{}\".format(yesterday, keyword)  # Keyword\n",
    "        searchTwitterAPI(keyword=keyword, since=yesterday, until=till).to_csv(\"../Daten/TwitterApi/{}/{}.csv\".format(yesterday, filename), sep = ';', line_terminator = '', encoding = 'utf-8')\n",
    "\n",
    "# Holt sich in einem Zeitraum Tweets mit einer Keywordliste\n",
    "def getTwitterBetweenDates(fromDate, tillDate, keywords):\n",
    "    fromThisDate = datetime.datetime.strptime(fromDate, \"%Y-%m-%d\")\n",
    "    toThisDate = datetime.datetime.strptime(tillDate, \"%Y-%m-%d\")\n",
    "    listWithDates = pd.date_range(fromThisDate,(toThisDate-pd.to_timedelta(1,'d')),freq='d')\n",
    "    #print(listWithDates[-1:].strftime(\"%Y-%m-%d\"))\n",
    "    for date in listWithDates:\n",
    "        getTwitterFromDay(date.strftime(\"%Y-%m-%d\"), keywords)\n",
    "    print(\"Ende\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competent-annex",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords = readKeywordFile(\"./KeywordsGER.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-manor",
   "metadata": {},
   "source": [
    "OAuth 2 Authentication (Limit: 450 x 100 pro 15min).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-trade",
   "metadata": {},
   "source": [
    "Nur die letzten 7 Tage sind hiermit möglich!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "monthly-catalyst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auth = tw.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True, retry_count=5,retry_errors=set([401, 404, 500, 503]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outdoor-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming to json\n",
      "Ende\n"
     ]
    }
   ],
   "source": [
    "job_EveryDay(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-silicon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Jeden Tag selbstständig Daten holen\n",
    "schedule.every().day.at(\"09:00\").do(job_EveryDay, keywords)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60) # Check every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "immune-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTwitterFromDay(\"2021-03-23\", keywords[60:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polyphonic-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTwitterBetweenDates(\"2021-03-15\", \"2021-03-18\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-trust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "d8b32da32ca45bacd67e9a08daee70a5eca111f4e7e40040cf40975fa2bf4d1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}